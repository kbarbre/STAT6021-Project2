---
title: "The Effect of Beauty and Other Characteristics on Professor Evaluation Ratings"
author: "Katelyn Barbre, Samuel Shaud, Isaac Stevens, Melanie Sattler"
date: "10/29/2020"
header_includes:
  - \usepackage{setspace}\doublespacing
  - \usepackage{amsmath}
output: pdf_document
mainfont: Times New Roman
fontsize: 12pt
---

```{r, include= FALSE}
knitr::purl('Project-2.Rmd')
```

```{r, include=FALSE}
library(AER)
library(dplyr)
library(ROCR)
library(nnet)
library(leaps)
library(faraway)
library(MASS)
library(glmnet)

data(TeachingRatings)
data <- TeachingRatings
```

# Summary

Typing words outside of chunks will be the paragraphs that show up in the PDF.

# Exploratory Data Analysis

Typing words outside of chunks will be the paragraphs that show up in the PDF.

```{r message=FALSE, warning=FALSE, include=FALSE}
#How many times is the same professor evaluated
prof_rated <- data %>%
  distinct() %>%
  count(prof)

#Count each professor to aggregate to histogram
prof_rated_again <- prof_rated %>%
  distinct() %>%
  count(n)
```

```{r,echo=FALSE,fig.height = 4, fig.width = 6, fig.align = "center"}
#Histogram of how many times professors were rated
bp <- barplot(prof_rated_again$nn, col = 'skyblue3', main="Histogram for the Number of Times a Professor was Evaluated", ylab = "Number of Professors", xlab="Number of Times Evaluated")
axis(1, at = bp, cex.axis=1.2, labels = prof_rated_again$n)
```

```{r, echo=FALSE,fig.height = 4, fig.width = 6, fig.align = "center"}
#boxplot on evals without the transformation

par(mfrow=c(1,5))
boxplot(data$eval~data$gender, ylab= 'Evaluation Score', xlab= 'Gender')
boxplot(data$eval~data$minority, ylab= 'Evaluation Score', xlab= 'Minority')
boxplot(data$eval~data$native, ylab= 'Evaluation Score', xlab= 'Native')
boxplot(data$eval~data$tenure, ylab= 'Evaluation Score', xlab= 'Tenure')
boxplot(data$eval~data$division, ylab= 'Evaluation Score', xlab= 'Division')
```

```{r, include=FALSE}
#Turn Division Numeric
data['division'] <- lapply(data['division'], as.numeric)
data['division'] <- data['division'] - 1

#Group Variables by Professor
group.data <- summarize(group_by(tibble::as_tibble(data), prof), evals = mean(eval), beaut = mean(beauty), age = mean(age), gender = first(gender), age = first(age), minority = first(minority), native = first(native), tenure = first(tenure), division = mean(division), students = mean(students), allstudents = mean(allstudents))
group.data <- subset(group.data, select = -c(prof))

attach(group.data)

```




# Simple Linear Regression

Our first goal for the data was to determine whether or not there was a linear relationship between a professors perceived beauty and their class evaluation scores. When looking at the scatter plot and corresponding regression line, there appears to be a weak relationship. 

```{r, include=FALSE}
#scatter plot of evaluation score against beauty
plot(data$eval~data$beauty)

#no clear linear pattern
```

```{r, include=FALSE}
#now time to re-plot beauty and eval to see if there is a linear relationship
plot(evals~beaut, data = group.data)

#seems to be more of a linear relationship
```

```{r, echo=FALSE,fig.height = 4, fig.width = 6, fig.align = "center"}
slr.result <- lm(evals~beaut, data = group.data)
plot(evals~beaut, data = group.data, xlab = 'Beauty Rating', ylab = 'Evaluation Score', main = 'Evaluation Score Against Beauty with Regression Line')
abline(slr.result, col = 'red')
```
The summary statistics for the regression line show that the coefficient is only significant at a 90% confidence level. That would be an acceptable confidence level for some industries, but the more disturbing statistic is the $R^2$ value. The closer the $R^2$ value is to zero, the more likely it is that the regression line does not fit the data well. Since the $R^2$ value is 3.85%, we can conclude that the regression model does not predict the variation in the data very well at all. 

```{r, echo=FALSE, fig.center = 'center'}
summary(slr.result)
#the coefficient is only significant at alpha = .10
```

```{r, include=FALSE}
#######################################################################################################
## Since the model does not fit the data well, the assumptions do not necessarily need to be reported.
#######################################################################################################

plot(slr.result$residuals~slr.result$fitted.values)
abline(h=0, col='red')
#constant variance assumptions seems to be met

acf(slr.result$residuals)
#correlation issue at lag = 5

qqnorm(slr.result$residuals)
qqline(slr.result$residuals, col="red")
#linearity assumption is not quite met, but is the least important

#confidence interval for non-transformed data
confint(slr.result, level = 0.95)
```

Since the original question did not produce a satisfactory model, we were curious if there were any simple linear regression models that predicted the evaluation score better than beauty rating. After running all subsets of simple linear regression, only two models had significant predictors: evaluation score against the percentage of upper division classes and number of students that took the evaluation. However, similarly to the beauty model, the $R^2$ value shows that the regression equation accounts for almost none of the variation in the data.

```{r, include=FALSE}
alt.slr1 <- lm(evals~age)
summary(alt.slr1)
alt.slr2 <- lm(evals~division)
summary(alt.slr2)
alt.slr3 <- lm(evals~students)
summary(alt.slr3)
```



# Multiple Linear Regression

Typing words outside of chunks will be the paragraphs that show up in the PDF.

```{r, include=FALSE}
##intercept only model
regnull <- lm(evals~1, data=group.data)
##model with all predictors
regfull <- lm(evals~., data=group.data)

##forward selection, backward elimination, and stepwise regression
step(regnull, scope=list(lower=regnull, upper=regfull), direction="forward")
step(regfull, scope=list(lower=regnull, upper=regfull), direction="backward")
step(regnull, scope=list(lower=regnull, upper=regfull), direction="both")

#The model created is evals ~division + beaut + gender + tenure + native by both the forward and step-wise
```

```{r, include=FALSE}
#########################################################
#model used is the one created by forward and step-wise 
#Multpile linear regression 
#Partial F-tests to verify the model 

#This is the full model that includes all predictors except Prof since that is grouped 
fullresult<- lm(evals ~division + beaut + gender + tenure + native+age+students+allstudents+minority)
summary(fullresult)
anova(fullresult)
```

```{r, include=FALSE}
#result1 is the model created by the Forward and step-wise functions 
result1<- lm(evals ~division + beaut + gender + tenure + native)
summary(result1)
anova(result1)
```

```{r, echo=FALSE}
##Partial F test for reduced model created by model building steps 
anova(result1, fullresult)
```

```{r, include=FALSE}
#Result2 is the model but we in addition drop native from the result1 model 
result2<-lm(evals~division+beaut+gender+tenure)
summary(result2)
anova(result2)
```

```{r, echo=FALSE}
##Partial F-test to see if we can drop native
anova(result2,fullresult)

#Based on the partial F-test the final model is evals~division+beaut+gender+tenure
```

```{r, echo=FALSE,fig.height = 4, fig.width = 6, fig.align = "center"}
#########################################################################
######################################################################
###Checking regression assumptions are met for Model 1evals ~division + beaut + gender + tenure + native 
##residual plot
plot(result1$fitted.values,result1$residuals, main="Plot of Residuals against Fitted Values for Model 1")
abline(h=0,col="red")
```

```{r,echo=FALSE,fig.height = 4, fig.width = 6, fig.align = "center"}
##acf plot of residuals
acf(result1$residuals)
```

```{r, echo=FALSE,fig.height = 4, fig.width = 6, fig.align = "center"}
##qq plot of residuals
qqnorm(result1$residuals)
qqline(result1$residuals, col="red")
```

```{r, echo=FALSE,fig.height = 4, fig.width = 6, fig.align = "center"}
##########################################################################
######################################################################
###Checking regression assumptions are met for Model 1evals ~division + beaut + gender + tenure
##residual plot
plot(result2$fitted.values,result2$residuals, main="Plot of Residuals against Fitted Values for Model 2")
abline(h=0,col="red")
```

```{r, echo=FALSE,fig.height = 4, fig.width = 6, fig.align = "center"}
##acf plot of residuals
acf(result2$residuals)
```

```{r, echo=FALSE,fig.height = 4, fig.width = 6, fig.align = "center"}
##qq plot of residuals
qqnorm(result2$residuals)
qqline(result2$residuals, col="red")
```

```{r, echo=FALSE,fig.height = 4, fig.width = 6, fig.align = "center"}
######################################################
####################################################33
#Looking for potential outliers
##residuals
#Based on model 1/reduced1 

residuals1<-result1$residuals 

##studentized residuals
student.res<-rstandard(result1) 

##externally studentized residuals
ext.student.res<-rstudent(result1) 

par(mfrow=c(1,3))
plot(result1$fitted.values,residuals1,main="Residuals")
plot(result1$fitted.values,student.res,main="Studentized Residuals")
plot(result1$fitted.values,ext.student.res,main="Externally Studentized Residuals")
```

```{r, include=FALSE}
n<-length(evals)
p<-6 #one intercept and 5 predictors 

##critical value using Bonferroni procedure
qt(1-0.05/(2*n), n-p-1)

sort(ext.student.res)
```

```{r, echo=FALSE,fig.height = 4, fig.width = 6, fig.align = "center"}
plot(ext.student.res,main="Externally Studentized Residuals", ylim=c(-4,4))
abline(h=qt(1-0.05/(2*n), n-p-1), col="red")
abline(h=-qt(1-0.05/(2*n), n-p-1), col="red")
```

```{r, include=FALSE}
ext.student.res[abs(ext.student.res)>qt(1-0.05/(2*n), n-p-1)]

##leverages
lev<-lm.influence(result1)$hat 

sort(lev)
2*p/n
```

```{r, echo=FALSE,fig.height = 4, fig.width = 6, fig.align = "center"}
plot(lev, main="Leverages", ylim=c(0,0.4))
abline(h=2*p/n, col="red")
```

```{r, include=FALSE}

lev[lev>2*p/n]

##influential observations
DFFITS<-dffits(result1)
DFFITS[abs(DFFITS)>2*sqrt(p/n)]

DFBETAS<-dfbetas(result1)
DFBETAS[abs(DFBETAS)>2/sqrt(n)]

COOKS<-cooks.distance(result1)
COOKS[COOKS>qf(0.5,p,n-p)]
```



# Logistic Regression

Another one of our questions was whether or not age, beauty rating, and the percentage of upper level classes taught could predict the gender of a professor. Since gender is a binomial response variable, we used a logistic regression model. However when fitting the model, the regression coefficients do not seem to be significant. To test this, we used a ____ test with $H_0: \beta_{age}=\beta_{beauty} = \beta_{division} = 0$ and $H_1:$ at least $\beta_{age}$, $\beta_{beauty}$, or $\beta_{division}$ does not equal zero. The p-value for the test came out to be 0.1078. Thus we fail to reject the null hypothesis with 95% confidence and conclude that the three coefficients are zero.

```{r, echo=FALSE}
#using gender as the response variable and age, beauty, and division as predictors
log.result <- glm(gender~age+beaut+division, family='binomial', data= group.data)
summary(log.result)
```

```{r, include=FALSE}
#test if all 3 coefficients are zero
1-pchisq(log.result$null.deviance-log.result$deviance, 3)

#fail to reject the null hypothesis, all the coefficients are zero
```

With this result, we were not satisfied. Therefore we came up with a new query regarding the ability to predict a professor's tenure status using the other predictors in the model. The summary output for this model is slightly more promising with some predictors appearing to be significant. We ran a ___ test to be sure at least one of the coefficients was non-zero and a p-value of 0.0078 confirms that.

```{r, echo=FALSE}
#can a subset of the variables predict whether the professor is tenured?
log.result2 <- glm(tenure~evals+age+gender+minority+native+division, family='binomial', data=group.data)
summary(log.result2)
```

```{r, include=FALSE}
#test if all 4coefficients are zero
1-pchisq(log.result2$null.deviance-log.result2$deviance, 3)

#reject the null hypothesis, at least one coefficient is not zero
```

To help narrow down the necessary coefficients, we used forward, backward, and step-wise model selection techniques. All three techniques came up with the same model: evaluation being predicted by age and evaluation score. Although this is an interesting result, the summary shows that the age predictor may not be significant. Therefore we ran a ____ test to see whether or not the age coefficient was zero. The corresponding p-value for the test was 0.4333, meaning we can drop age from the regression model since it is zero.

```{r, include=FALSE}
#using forward model selection to find the best model
regfull <- glm(tenure~evals+age+gender+minority+native+division, family='binomial', data=group.data)
regnull <- glm(tenure~1, family='binomial', data=group.data)

step(regnull, scope=list(lower=regnull, upper=regfull), direction="forward")

#using backward model selection to find the best model
step(regfull, scope=list(lower=regnull, upper=regfull), direction="backward")

#using stepwise model selection to find the best model
step(regnull, scope=list(lower=regnull, upper=regfull), direction="both")

```

```{r, echo=FALSE}
#all selection methods arrive at the same conclusion
bestlog.result <- glm(tenure~evals+age, family='binomial', data=group.data)
summary(bestlog.result)
```

```{r, include=FALSE}
# since age is not significant, let's check to see if it should be dropped
reduced <- glm(tenure~evals, family='binomial', data=group.data)
1-pchisq(reduced$deviance-bestlog.result$deviance,1)

#fail to reject the null hypothesis, thus we can safely remove age as a predictor
```

With the zero coefficient removed, our final log regression model for predicting the tenure of a professor was down to the evaluation score. The summary output shows the coefficient is significant at a 90% confidence level

```{r,echo=FALSE}
finalLog.result <- glm(tenure~evals, family='binomial', data=group.data)
summary(finalLog.result)
```

```{r, include=FALSE}
#hypothesis test to see if the result is significant
1-pchisq(finalLog.result$null.deviance-finalLog.result$deviance,1)
```

## Log Regression Model Validation

Since we have a regression model

```{r, include=FALSE}
#set seed
set.seed(111)

#split the data into train and test
sample<-sample.int(nrow(group.data), floor(.50*nrow(group.data)), replace = F)
train<-group.data[sample, ]
test<-group.data[-sample, ]

#fit the model with the training data
val.result <- glm(tenure~evals, family='binomial', data=train)

##predicted survival rate for testing data based on training data
preds<-predict(val.result,newdata=test, type="response")

##produce the numbers associated with classification table
rates<-prediction(preds, test$tenure)

##store the true positive and false postive rates
roc_result<-performance(rates,measure="tpr", x.measure="fpr")
```

```{r, echo=FALSE,fig.height = 4, fig.width = 6, fig.align = "center"}
##plot ROC curve and overlay the diagonal line for random guessing
plot(roc_result, main="ROC Curve for Tenure")
lines(x = c(0,1), y = c(0,1), col="red")
```

```{r, include=FALSE}
##compute the AUC
aucvalues <- performance(rates, measure = "auc")
auc <- aucvalues@y.values[[1]]
auc

#auc is 0.7616959 which is halfway between perfect (1.0) and random (0.5)
```

```{r, echo=FALSE}
##confusion matrix. Actual values in the rows, predicted classification in cols
table(test$tenure, preds>0.5)

table(test$tenure, preds>0.7)
```


# Ridge/Lasso Regression

```{r, include=FALSE}
#Turn Into Matrix
x<-model.matrix(evals ~ division + beaut + gender + tenure + native + students,group.data)[,-1]
y<-group.data$evals

#Split data into train and test
set.seed(2020)
train<-sample(1:nrow(x), nrow(x)/2)
test<-(-train)
y.test<-y[test]

#Fit Ridge Regression
set.seed(4630)
cv.ridge.out<-cv.glmnet(x[train,],y[train],alpha=0)
coefficients(cv.ridge.out)
bestlam.ridge<-cv.ridge.out$lambda.min
bestlam.ridge
```

```{r, echo=FALSE,fig.height = 4, fig.width = 6, fig.align = "center"}
plot(cv.ridge.out)
```

```{r, include=FALSE}
##fit ridge regression using training data
ridge.mod<-glmnet(x[train,],y[train],alpha=0,lambda=bestlam.ridge, thresh = 1e-14)
##Test MSE with best lambda
ridge.pred<-predict(ridge.mod,s=bestlam.ridge,newx=x[test,])
mean((ridge.pred-y.test)^2)
```

```{r, include=FALSE}
#Fit Lasso Regression
set.seed(4630)
cv.lasso.out<-cv.glmnet(x[train,],y[train],alpha=1)
bestlam.lasso<-cv.lasso.out$lambda.min
bestlam.lasso
```

```{r, echo=FALSE,fig.height = 4, fig.width = 6, fig.align = "center"}
plot(cv.lasso.out)
```

```{r, include=FALSE}
##fit lasso regression using training data
lasso.mod<-glmnet(x[train,],y[train],alpha=1,lambda=bestlam.lasso, thresh = 1e-14)
coefficients(lasso.mod)
##Test MSE with best lambda
lasso.pred<-predict(lasso.mod,s=bestlam.lasso,newx=x[test,])
mean((lasso.pred-y.test)^2)

#Fit OLS
OLS<-glmnet(x[train,],y[train],alpha=0,lambda=0, thresh = 1e-14)
OLS.pred<-predict(OLS,newx=x[test,])
mean((OLS.pred-y.test)^2)

##Compare ridge with OLS using best lambda and all observations
cbind(coefficients(ridge.mod), coefficients(OLS))
```

```{r, echo=FALSE,fig.height = 4, fig.width = 6, fig.align = "center"}
#Create Ridge Plots
#Ridge Plot
grid<-10^seq(10,-2,length=100)
out.ridge.all<-glmnet(x,y,alpha=0,lambda=grid,thresh = 1e-14)
plot(out.ridge.all, xvar = "lambda")
abline(v=log(bestlam.ridge), lty=2)
legend("bottomright", lwd = 1, col = 1:6, legend = colnames(x), cex = .7)
```

```{r, echo=FALSE,fig.height = 4, fig.width = 6, fig.align = "center"}
#Lasso Ridge Plot
grid<-10^seq(10,-2,length=100)
out.lasso.all<-glmnet(x,y,alpha=1,lambda=grid,thresh = 1e-14)
plot(out.lasso.all, xvar = "lambda")
abline(v=log(bestlam.lasso), lty=2)
legend("bottomright", lwd = 1, col = 1:6, legend = colnames(x), cex = .7)
```

```{r, echo=False}
#This is a test
```


